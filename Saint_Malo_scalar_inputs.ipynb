{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f08ad3e",
   "metadata": {},
   "source": [
    "# Exemple sur le modèle jouet Campbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1d45878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gpflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "928c297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import model_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e1294",
   "metadata": {},
   "source": [
    "On récupère les entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c7ca6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.5 2.  2.5 3. ]\n",
      "taille de x_train: (55, 2)\n"
     ]
    }
   ],
   "source": [
    "hs_list = np.arange(1, 3.1, 0.5)\n",
    "msl_list = np.arange(0, 1.1, 0.1)\n",
    "print(hs_list)\n",
    "x_train=[]\n",
    "for hs in hs_list:\n",
    "    for msl in msl_list:\n",
    "        x_train.append([hs,msl])\n",
    "x_train=np.array(x_train)\n",
    "print(\"taille de x_train:\",x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4259302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de y_train : (55, 2929740)\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"data_malo_GP\"\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for hs in hs_list:\n",
    "    for msl in msl_list:\n",
    "\n",
    "        folder_name = f\"run_msl_{msl:.1f}_hs_{hs:.1f}\"\n",
    "        file_path = os.path.join(base_folder, folder_name, \"scattered_map_final.bin\")\n",
    "\n",
    "        # Lecture du fichier binaire\n",
    "        data = np.fromfile(file_path, dtype=np.float32)\n",
    "\n",
    "\n",
    "        y_train.append(data)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "print(\"Taille de y_train :\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4891b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: float32\n",
      "Présence de NaN: True\n",
      "Présence d'infini: False\n",
      "min = -3.4027969e+38\n",
      "max = 3.402817e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = nan\n",
      "std = nan\n"
     ]
    }
   ],
   "source": [
    "print(\"type:\",y_train.dtype)\n",
    "print(\"Présence de NaN:\",np.isnan(y_train).any())\n",
    "print(\"Présence d'infini:\",np.isinf(y_train).any())\n",
    "print(\"min =\", np.nanmin(y_train))\n",
    "print(\"max =\", np.nanmax(y_train))\n",
    "print(\"mean =\", np.nanmean(y_train))\n",
    "print(\"std =\", np.nanstd(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08446ff4",
   "metadata": {},
   "source": [
    "On a des valeurs extrèmes et des NaN :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8fccbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb NaN       : 258076\n",
      "nb extrêmes  : 8730492\n"
     ]
    }
   ],
   "source": [
    "mask_extreme = np.abs(y_train) > 1e30\n",
    "np.where(mask_extreme)\n",
    "print(\"nb NaN       :\", np.isnan(y_train).sum())\n",
    "print(\"nb extrêmes  :\", mask_extreme.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14108e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb NaN       : 0\n",
      "nb extrêmes  : 0\n"
     ]
    }
   ],
   "source": [
    "y_train_clean = np.where(mask_extreme, np.nan, y_train)\n",
    "y_train_clean = np.nan_to_num(y_train_clean, nan=0.0)\n",
    "\n",
    "mask_extreme = np.abs(y_train_clean) > 1e30\n",
    "np.where(mask_extreme)\n",
    "print(\"nb NaN       :\", np.isnan(y_train_clean).sum())\n",
    "print(\"nb extrêmes  :\", mask_extreme.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5ce0334",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc = 5  # On choisit arbitrairement le nombre de composantes principales (d'après la thèse, 5 semble un bon compromis)\n",
    "theta = 3 # On choisit arbitrairement la valeur de theta \n",
    "sigma = 1 # et de sigma\n",
    "param = [theta, sigma]\n",
    "\n",
    "kernel = gpflow.kernels.SquaredExponential(lengthscales=param[0], variance=param[1]**2) + gpflow.kernels.White(variance=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf1a2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:775: RuntimeWarning: overflow encountered in square\n",
      "  self.explained_variance_ = (S**2) / (n_samples - 1)\n",
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:786: RuntimeWarning: overflow encountered in square\n",
      "  X_centered **= 2\n",
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:789: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "c:\\Users\\Victor\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:793: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  self.noise_variance_ = total_var - xp.sum(self.explained_variance_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entraînement du modèle GP pour la composante principale  1 ---\n",
      "Modèle GP créé pour la composante principale  1 . Optimisation des hyperparamètres...\n",
      "Optimisation terminée.\n",
      "\n",
      "--- Entraînement du modèle GP pour la composante principale  2 ---\n",
      "Modèle GP créé pour la composante principale  2 . Optimisation des hyperparamètres...\n",
      "Optimisation terminée.\n",
      "\n",
      "--- Entraînement du modèle GP pour la composante principale  3 ---\n",
      "Modèle GP créé pour la composante principale  3 . Optimisation des hyperparamètres...\n",
      "Optimisation terminée.\n",
      "\n",
      "--- Entraînement du modèle GP pour la composante principale  4 ---\n",
      "Modèle GP créé pour la composante principale  4 . Optimisation des hyperparamètres...\n",
      "Optimisation terminée.\n",
      "\n",
      "--- Entraînement du modèle GP pour la composante principale  5 ---\n",
      "Modèle GP créé pour la composante principale  5 . Optimisation des hyperparamètres...\n",
      "Optimisation terminée.\n",
      "--- Analyse en Composantes Principales ---\n",
      "Variance expliquée par les 5 premières composantes : [nan nan nan nan nan]\n",
      "Variance globale expliquée : nan\n",
      "Taille du jeu d'entrainement transformé par ACP : (55, 5)\n"
     ]
    }
   ],
   "source": [
    "# ACP\n",
    "ACP = model_class.ACP_classique(n_pc,[theta,sigma])\n",
    "ACP.train(x_train,y_train_clean,kernel_fn=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e9426",
   "metadata": {},
   "source": [
    "Bon bah ça à l'air de fonctionner, maintenant on peut voir ce que ca donne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "581c0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction en cours...\n",
      "MSE ACP sur données d'entraînement : 8.678455967099293e+56\n"
     ]
    }
   ],
   "source": [
    "Y_test_reconstruct_ACP = ACP.predict(x_train)  # On prédit sur les données d'entraînement pour vérifier la reconstruction\n",
    "mse_ACP = np.mean((y_train_clean - Y_test_reconstruct_ACP)**2)\n",
    "print(\"MSE ACP sur données d'entraînement :\", mse_ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b704d9b",
   "metadata": {},
   "source": [
    "Ah bah ca va pas du tout là !\n",
    "Je ne sais pas à quoi c'est lié..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
